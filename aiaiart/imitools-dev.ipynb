{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8a6cba-5a16-438c-9ad6-606a8bd1967c",
   "metadata": {},
   "source": [
    "# imitools Dev\n",
    "\n",
    "The devtool for imitools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63650e0-1a83-4218-b431-deea321701ff",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "* ~Introduce the wrap & from_path funtions~\n",
    "* ~convert the codebase to keep a list of pils~\n",
    "* ~support loading files from directories~\n",
    "* ~save a wrap to a disk (directory)~\n",
    "* ~create a video from a disk~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e472c46-09ea-4981-b2c3-378303db0180",
   "metadata": {},
   "source": [
    "## Later\n",
    "\n",
    "* ~multithreading support when saving images~\n",
    "* immutability when returning pil\n",
    "* add a map function\n",
    "* Download images from duckduck go\n",
    "* multithreading when reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac5c11a-4da7-40a4-bd4a-c8919c606ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fb0219-d50d-41e6-82f8-1217d571d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from pathlib import Path\n",
    "from IPython.display import  display, HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class ImageDefaults:\n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"\n",
    "        \n",
    "defaults = ImageDefaults()\n",
    "\n",
    "class VideoWrapper:\n",
    "    def __init__(self, video_path, video_size):\n",
    "        self.video_path = video_path\n",
    "        self.video_size = video_size\n",
    "        \n",
    "    def path(self):\n",
    "        return self.video_path\n",
    "    \n",
    "    def show(self):\n",
    "        mp4 = open(self.video_path, 'rb').read()\n",
    "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "        \n",
    "        width, height = self.video_size\n",
    "        \n",
    "        return HTML(f\"\"\"\n",
    "        <video width={width} height={height} controls>\n",
    "              <source src=\"%s\" type=\"video/mp4\">\n",
    "        </video>\n",
    "        \"\"\" % data_url)\n",
    "\n",
    "class ImageWrapper:\n",
    "    def __init__(self, data, image_type):\n",
    "        self.data = data\n",
    "        self.image_type = image_type\n",
    "        \n",
    "    def resize(self, size=(256, 256)) -> ImageWrapper:\n",
    "        if self.image_type != \"pil\":\n",
    "            raise Exception(\"resize() only applied for pil images\")\n",
    "            \n",
    "        if isinstance(size, int):\n",
    "            size = (size, size)\n",
    "            \n",
    "        new_images = [im.resize(size) for im in self.data]\n",
    "        return ImageWrapper(new_images, \"pil\")\n",
    "    \n",
    "    def normalize(self) -> ImageWrapper:\n",
    "        if self.image_type != \"pt\":\n",
    "            raise Exception(\"normalize() only applied for pytorch tensors\")\n",
    "        \n",
    "        normalized = (self.data - self.data.min()) / (self.data.max() - self.data.min())\n",
    "        return ImageWrapper(normalized, \"pt\")\n",
    "    \n",
    "    def sinrange(self) -> ImageWrapper:\n",
    "        if self.image_type != \"pt\":\n",
    "            raise Exception(\"sinrange() only applied for pytorch tensors\")\n",
    "        \n",
    "        return ImageWrapper(self.data * 2 - 1, \"pt\")\n",
    "        \n",
    "    def pil(self) -> Image:\n",
    "        if self.image_type == \"pil\":\n",
    "            return self.data[0] if len(self.data) == 1 else self.data\n",
    "        \n",
    "        if self.image_type == \"pt\":\n",
    "            make_pil = transforms.ToPILImage()\n",
    "            pt_images = self.data.cpu()\n",
    "            pil_images = [make_pil(i) for i in pt_images]\n",
    "            return pil_images[0] if len(pil_images) == 1 else pil_images\n",
    "    \n",
    "    def pt(self) -> torch.Tensor:            \n",
    "        if self.image_type == \"pil\":\n",
    "            pt_images = [transforms.ToTensor()(im) for im in self.data]\n",
    "            return torch.stack(pt_images).to(defaults.device)\n",
    "        \n",
    "        if self.image_type == \"pt\":\n",
    "            return self.data\n",
    "        \n",
    "    def to(self, device=\"cpu\") -> ImageWrapper:\n",
    "        if self.image_type != \"pt\":\n",
    "            raise Exception(\"to() only applied for pytorch tensors\")\n",
    "        \n",
    "        return ImageWrapper(self.data.to(device), \"pt\")\n",
    "    \n",
    "    def cpil(self) -> ImageWrapper:\n",
    "        images = self.pil()\n",
    "        if isinstance(images, Image.Image):\n",
    "            images = [images]\n",
    "            \n",
    "        return ImageWrapper(images, \"pil\")\n",
    "    \n",
    "    def cpt(self) -> ImageWrapper:\n",
    "        return ImageWrapper(self.pt(), \"pt\")\n",
    "    \n",
    "    def show(self, cmap=None, figsize=None, cols=6, max_count=36, scale=2.5, captions=True):        \n",
    "        if len(self.data) == 1:\n",
    "            plt.axis(\"off\")\n",
    "            if self.image_type == \"pil\":\n",
    "                plt.imshow(self.data[0], cmap=cmap)\n",
    "            else:\n",
    "                plt.imshow(self.data[0].permute(1, 2, 0).cpu(), cmap=cmap)\n",
    "                \n",
    "            return\n",
    "        \n",
    "        images = self.data.cpu() if self.image_type == \"pt\" else self.data\n",
    "        image_count = len(self.data)\n",
    "        \n",
    "        if image_count > max_count:\n",
    "            images = self.data[0:max_count]\n",
    "            print(f\"found {image_count} images to show. But only showing {max_count}\")\n",
    "            \n",
    "        if image_count < cols:\n",
    "            cols = image_count\n",
    "            \n",
    "        rows = math.ceil(image_count / cols)\n",
    "        \n",
    "        if figsize == None:\n",
    "            figsize = figsize=(cols*scale, rows*scale)\n",
    "            \n",
    "        _, ax = plt.subplots(rows, cols, figsize=figsize)\n",
    "        if (rows == 1):\n",
    "            for i in range(image_count):\n",
    "                image = images[i] if self.image_type == \"pil\" else images[i].permute(1, 2, 0)\n",
    "                ax[i].imshow(image)\n",
    "                ax[i].axis(\"off\")\n",
    "                if captions: ax[i].set_title(f\"{i}\")\n",
    "        else:\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    i = row * cols + col\n",
    "                    if i < image_count:\n",
    "                        image = images[i] if self.image_type == \"pil\" else images[i].permute(1, 2, 0)\n",
    "                        ax[row][col].imshow(image)\n",
    "                        ax[row][col].axis(\"off\")\n",
    "                        if captions: ax[row][col].set_title(f\"{i}\")\n",
    "                    else:\n",
    "                        ax[row][col].axis(\"off\")\n",
    "                        \n",
    "    def to_dir(self, output_dir, prefix=\"image\", max_workers=min(10, os.cpu_count())):\n",
    "        if self.image_type != \"pil\":\n",
    "            raise Exception(\"to_dir() only applied for pil images\")\n",
    "            \n",
    "        dir_path = Path(output_dir)\n",
    "        dir_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        images = self.data\n",
    "\n",
    "        def save_image(i):\n",
    "            try:\n",
    "                path = Path(output_dir)/f\"{prefix}_{i:04}.png\"\n",
    "                images[i].save(path)\n",
    "            except Exception as e:\n",
    "                print(\"image saving error:\", e)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            return executor.map(save_image, range(len(images)), timeout=60)\n",
    "            \n",
    "    def to_video(self, out_path=None, frame_rate=12):\n",
    "        if self.image_type != \"pil\":\n",
    "            raise Exception(\"to_video() only applied for pil images\")\n",
    "            \n",
    "        id = int(torch.rand(1)[0].item() * 9999999)\n",
    "        image_dir = Path(f'/tmp/{id}/images')\n",
    "        image_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        if out_path == None:\n",
    "            out_path = f\"/tmp/{id}/video.mp4\"\n",
    "\n",
    "        video_path = Path(out_path)\n",
    "        video_size = self.data[0].size\n",
    "        images_selector = image_dir/\"image_%04d.png\"\n",
    "        \n",
    "        self.to_dir(image_dir, prefix=\"image\")\n",
    "\n",
    "        command = f\"ffmpeg -v 0 -y -f image2 -framerate {frame_rate} -i {images_selector} -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p {video_path}\"\n",
    "        os.system(command)\n",
    "    \n",
    "        return VideoWrapper(video_path, video_size)\n",
    "\n",
    "def wrap(input_data) -> ImageWrapper:\n",
    "    if isinstance(input_data, ImageWrapper):\n",
    "        return input_data\n",
    "    \n",
    "    if isinstance(input_data, torch.Tensor):\n",
    "        if len(input_data.shape) == 3:\n",
    "            input_data = input_data.unsqueeze(0)\n",
    "            \n",
    "        return ImageWrapper(input_data.detach(), \"pt\")\n",
    "    \n",
    "    if isinstance(input_data, Image.Image):\n",
    "        return ImageWrapper([input_data], \"pil\")\n",
    "    \n",
    "    if isinstance(input_data, list):\n",
    "        if isinstance(input_data[0], torch.Tensor):\n",
    "            images = torch.stack(input_data).squeeze(1).detach()\n",
    "            return ImageWrapper(images, \"pt\")\n",
    "        \n",
    "        if isinstance(input_data[0], Image.Image):\n",
    "            return ImageWrapper(input_data, \"pil\")\n",
    "        \n",
    "        if isinstance(input_data[0], ImageWrapper):\n",
    "            image_list = list(map(lambda w: w.pt(), input_data))\n",
    "            images = torch.stack(image_list).squeeze(1).detach()\n",
    "            return ImageWrapper(images, \"pt\")\n",
    "    \n",
    "    raise Exception(\"not implemented!\")                        \n",
    "                        \n",
    "def from_dir(dir_path) -> ImageWrapper:\n",
    "    file_list = [f for f in Path(dir_path).iterdir() if not f.is_dir()]\n",
    "    image_list = []\n",
    "\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            image_list.append(Image.open(f).convert(\"RGB\"))\n",
    "        except UnidentifiedImageError:\n",
    "            None\n",
    "            \n",
    "    return ImageWrapper(image_list, \"pil\")\n",
    "\n",
    "def from_path(input_data) -> ImageWrapper:\n",
    "    pil_image = Image.open(input_data).convert(\"RGB\")\n",
    "    return ImageWrapper([pil_image], \"pil\")\n",
    "                        \n",
    "\n",
    "class DynaPlot:\n",
    "    def __init__(self, cols=2, figsize=(15, 4)):\n",
    "        fig, subplots = plt.subplots(1, cols, figsize=(20, 5))\n",
    "        fig.patch.set_facecolor(\"white\")\n",
    "        fig.tight_layout()\n",
    "        out = display(fig, display_id=True)\n",
    "\n",
    "        self.cols = cols\n",
    "        self.fig = fig\n",
    "        self.out = out\n",
    "        self.subplots = subplots\n",
    "        \n",
    "        self.queue = []\n",
    "        \n",
    "    def plot(self, subplot_id, *args, **kwargs) -> DynaPlot:\n",
    "        self.queue.append((\n",
    "            \"plot\", subplot_id, args, kwargs\n",
    "        ))\n",
    "        return self\n",
    "    \n",
    "    def title(self, subplot_id, title)-> DynaPlot:\n",
    "        self.queue.append((\n",
    "            \"title\", subplot_id, title\n",
    "        ))\n",
    "        return self\n",
    "        \n",
    "    def imshow(self, subplot_id, image)-> DynaPlot:\n",
    "        self.queue.append((\n",
    "            \"imshow\", subplot_id, image\n",
    "        ))\n",
    "        return self\n",
    "        \n",
    "    def update(self):\n",
    "        for col in range(self.cols):\n",
    "            if self.cols == 1:\n",
    "                self.subplots.clear()\n",
    "            else:\n",
    "                self.subplots[col].clear()\n",
    "        \n",
    "        for item in self.queue:\n",
    "            if item[0] == \"imshow\":\n",
    "                _, subplot_id, image = item\n",
    "                if self.cols == 1:\n",
    "                    self.subplots.imshow(wrap(image).pt().detach().cpu()[0].permute(1, 2, 0))\n",
    "                    self.subplots.axis(\"off\")\n",
    "                else:\n",
    "                    self.subplots[subplot_id].imshow(wrap(image).pt().detach().cpu()[0].permute(1, 2, 0))\n",
    "                    self.subplots[subplot_id].axis(\"off\")\n",
    "            \n",
    "            if item[0] == \"plot\":\n",
    "                _, subplot_id, args, kwargs = item\n",
    "                self.subplots[subplot_id].plot(*args, **kwargs)\n",
    "                if \"label\" in kwargs:\n",
    "                    self.subplots[subplot_id].legend()\n",
    "                \n",
    "            if item[0] == \"title\":\n",
    "                _, subplot_id, title = item\n",
    "                self.subplots[subplot_id].title.set_text(title)\n",
    "                \n",
    "        self.queue = []\n",
    "        self.out.update(self.fig)\n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "    \n",
    "def dplot(**kwargs) -> DynaPlot:\n",
    "    return DynaPlot(**kwargs)\n",
    "\n",
    "class ImiTools:\n",
    "    def __init__(self):\n",
    "        self.defaults = defaults\n",
    "        \n",
    "    def wrap(self, path) -> ImageWrapper:\n",
    "        return wrap(path)\n",
    "                        \n",
    "    def from_path(self, path) -> ImageWrapper:\n",
    "        return from_path(path)\n",
    "    \n",
    "    def from_dir(self, path) -> ImageWrapper:\n",
    "        return from_dir(path)\n",
    "    \n",
    "    def dplot(self, **kwargs) -> DynaPlot:\n",
    "        return dplot(**kwargs)\n",
    "    \n",
    "I = ImiTools()\n",
    "I.defaults.device = device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef24bcc3-ffd0-4f91-b975-60b59b59bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_images = torch.rand(100, 3, 256, 256)\n",
    "wrapper = I.wrap(pt_images).cpil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e000cd-09a4-4af1-bada-319ad2d82125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.94 s, sys: 31.7 ms, total: 1.97 s\n",
      "Wall time: 316 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x7fce6278ff20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time wrapper.to_dir(\"sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb5cfb-c193-4779-a75d-6e1aa649118b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
